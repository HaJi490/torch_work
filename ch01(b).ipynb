{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "821d2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader #mini_batch를 이용해서 큰 데이터를 작은데이터를 나눠서 계산할 준비\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68e291b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomDataset은 Dataset을 상속하고 \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor): #__: 매직메서드\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x) #batch_size로 나눌때 적당히 나누기 위해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6ebdcfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답지\n",
    "true_w = 2\n",
    "true_b = 1\n",
    "N = 100\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(N, 1)\n",
    "epsilon = 0.1 * np.random.randn(N, 1)   # ❗약간의 noise추가\n",
    "y = true_b + ( true_w * x) + epsilon\n",
    "\n",
    "# 8:2로 나눔\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "train_idx = idx[: int(N * 0.8)]\n",
    "val_idx = idx[int(N * 0.8): ]\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]\n",
    "\n",
    "# 모델\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)\n",
    "\n",
    "dataset = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75c9a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(nn.Linear(1,1)).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946bc582",
   "metadata": {},
   "source": [
    "#### 학습과 검증은 따로 간다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23c640df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용\n",
    "def make_train_step_fn(model, loss_fn, optimizer):\n",
    "    def perform_train_step_fn(x,y):\n",
    "            model.train()\n",
    "            yhat = model(x_train_tensor)\n",
    "            loss = loss_fn(yhat, y_train_tensor)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            return loss.item()\n",
    "    return perform_train_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6bb68227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용\n",
    "def make_val_step_fn(model, loss_fn):\n",
    "    def perform_train_step_fn(x,y):\n",
    "            model.eval()\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "            return loss.item()\n",
    "    return perform_train_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "77a09c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini_batch 사이즈(하이퍼파라미터: 내가 정하는)만큼 돌림 => mini_batch_loss값을 모음\n",
    "def mini_batch(device, data_loader, step_fn):\n",
    "    mini_batch_losses =[]\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57b0da5",
   "metadata": {},
   "source": [
    "++ 많이 돌린다고 좋은게 아님, 오차를 줄이는게 목적이다---!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2584c276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9690]])), ('0.bias', tensor([1.0235]))])\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "losses = [] # ❗관리대상(오차를 줄이는게 목적이니까)\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "for epoch in range(n_epochs):\n",
    "   loss = mini_batch(device, train_loader, train_step_fn)\n",
    "   losses.append(loss)\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "765819d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9690]])), ('0.bias', tensor([1.0235]))])\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "losses = [] \n",
    "val_losses = []\n",
    "\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "val_step_fn = make_val_step_fn(model, loss_fn)\n",
    "\n",
    "write = SummaryWriter(\"runs/simple_linear_regression\")\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "write.add_graph(model, x_sample.to(device))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "   # loss = mini_batch(device, train_loader, train_step_fn)\n",
    "   loss = mini_batch(device, train_loader, train_step_fn)\n",
    "   losses.append(loss)\n",
    "   with torch.no_grad():\n",
    "      val_loss = mini_batch(device, val_loader, val_step_fn)\n",
    "      val_losses.append(val_loss)\n",
    "   write.add_scalars(\n",
    "      main_tag=\"loss\",\n",
    "      tag_scalar_dict={\"training\": loss, \"validation\": val_loss},\n",
    "      global_step=epoch\n",
    "   )\n",
    "write.close()\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fcce823e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 232096), started 0:01:09 ago. (Use '!kill 232096' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6a1826a21fd63d07\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6a1826a21fd63d07\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811548b0",
   "metadata": {},
   "source": [
    "- 상속::\n",
    "    - 상위클래스의 기능을 하위클래스도 가지도록 ``강제``\n",
    "- 인터페이스::\n",
    "    - 계약 관계\n",
    "    - 타입안정성을 확보하기 위해서\n",
    "    - 설계관측자적 측면에서 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0106920",
   "metadata": {},
   "source": [
    "- ```파이썬은 인터페이스가 없음.```\n",
    "- 파이썬은 상속 안좋함 -> 내가 도대체 뭘 만들어줘야 할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "16ded1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.1960],\n",
       "         [0.7608],\n",
       "         [0.4722],\n",
       "         [0.0254],\n",
       "         [0.0055],\n",
       "         [0.7132],\n",
       "         [0.2713],\n",
       "         [0.3664],\n",
       "         [0.6075],\n",
       "         [0.0740],\n",
       "         [0.9219],\n",
       "         [0.0636],\n",
       "         [0.1849],\n",
       "         [0.7290],\n",
       "         [0.5613],\n",
       "         [0.0885]]),\n",
       " tensor([[1.4393],\n",
       "         [2.4970],\n",
       "         [1.9857],\n",
       "         [1.0785],\n",
       "         [1.0632],\n",
       "         [2.6162],\n",
       "         [1.5105],\n",
       "         [1.7093],\n",
       "         [2.4037],\n",
       "         [1.1713],\n",
       "         [2.8506],\n",
       "         [1.1928],\n",
       "         [1.5888],\n",
       "         [2.4927],\n",
       "         [2.0472],\n",
       "         [1.0708]])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6871d5",
   "metadata": {},
   "source": [
    "##  설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f785f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (8.3.152)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from ultralytics) (3.9.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (0.22.1+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.21.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596fd430",
   "metadata": {},
   "source": [
    "## 학습(커스텀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2807a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9bbd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new YOLO model from scratch\n",
    "model = YOLO(\"yolo11n.yaml\") # 제일 작은 모델()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "989e9d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\user\\Desktop\\torch_work\\bus.jpg: 640x480 4 persons, 1 bus, 31.3ms\n",
      "Speed: 2.1ms preprocess, 31.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "# Perform object detection on an image using the model\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")\n",
    "# results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f1e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export the model to ONNX format\n",
    "# success = model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97860f8",
   "metadata": {},
   "source": [
    "## 영상에 폭력적인 장면이 등장하면 바운딩박스를 그려주는 프로그램을 작성\n",
    "1. yolo -> 커스텀학습 ==> 모델\n",
    "2. 예측 -> 클래스 / box\n",
    "3. (결과)json, txt -> (MVC)controller -> view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de91c24",
   "metadata": {},
   "source": [
    "# 1. 커스텀 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50d4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import cv2\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51a655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11s.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9362b",
   "metadata": {},
   "source": [
    "⭐cdrive에 dataset만들어서 모아두기(가져가기 쉽게)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27e389e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.152  Python-3.9.21 torch-2.7.1+cu118 CPU (Intel Core(TM) i7-9700F 3.00GHz)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./data/violence/violence.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 304.4192.2 MB/s, size: 47.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\user\\Desktop\\torch_work\\data\\violence\\train\\labels.cache... 3518 images, 1537 backgrounds, 0 corrupt: 100%|██████████| 3518/3518 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 52.124.0 MB/s, size: 25.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\user\\Desktop\\torch_work\\data\\violence\\valid\\labels.cache... 3 images, 3 backgrounds, 0 corrupt: 100%|██████████| 3/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Labels are missing or empty in C:\\Users\\user\\Desktop\\torch_work\\data\\violence\\valid\\labels.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "Plotting labels to runs\\detect\\train7\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train7\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      1.385      1.603      1.659         11        640: 100%|██████████| 220/220 [50:36<00:00, 13.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\ultralytics\\utils\\metrics.py:585: RuntimeWarning: Mean of empty slice.\n",
      "  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\ultralytics\\utils\\metrics.py:630: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\ultralytics\\utils\\metrics.py:630: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\ultralytics\\utils\\metrics.py:630: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\ultralytics\\utils\\metrics.py:767: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "1 epochs completed in 0.844 hours.\n",
      "Optimizer stripped from runs\\detect\\train7\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from runs\\detect\\train7\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating runs\\detect\\train7\\weights\\best.pt...\n",
      "Ultralytics 8.3.152  Python-3.9.21 torch-2.7.1+cu118 CPU (Intel Core(TM) i7-9700F 3.00GHz)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\ultralytics\\utils\\metrics.py:585: RuntimeWarning: Mean of empty slice.\n",
      "  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\ultralytics\\utils\\metrics.py:630: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\ultralytics\\utils\\metrics.py:630: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\ultralytics\\utils\\metrics.py:630: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\user\\miniconda3\\envs\\torch-book\\lib\\site-packages\\ultralytics\\utils\\metrics.py:767: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n",
      "Speed: 3.4ms preprocess, 208.0ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_results= model.train(data='./data/violence/violence.yaml', epochs=1, imgsz=640, device='cpu') # 원래 epochs=20번정도 돌려야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9885a7",
   "metadata": {},
   "source": [
    "# 2. (학습된) 모델 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "585dd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('runs/detect/train7/weights/best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee84386",
   "metadata": {},
   "source": [
    "# 3. 영상에 해당 모델 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d96324c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frame_yolo(frame, model):\n",
    "    results = model(frame)\n",
    "    return results[0].boxes #box불러오기\n",
    "\n",
    "def draw_predictions(frame, predictions, class_names, conf_threshold=0.5):\n",
    "    for box in predictions:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "        conf = box.conf.item()\n",
    "        class_id = int(box.cls.item())\n",
    "\n",
    "        if conf >= conf_threshold:\n",
    "            label = f'{class_names[class_id]}({conf:.2f})'\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "            cv2.putText(frame, \n",
    "                        label, \n",
    "                        (int(x1), int(y1) - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)    #폰트, ...\n",
    "    return frame\n",
    "\n",
    "def process_video_yolo(input_path, output_path, model, class_names):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened:\n",
    "        return\n",
    "    # 속성값 확인\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.head()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        predictions = predict_frame_yolo(frame, model)\n",
    "        frame = draw_predictions(frame, predictions, class_names)\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1e466c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cv2.VideoCapture' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutputFighting028_x264.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m class_names \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mnames\n\u001b[1;32m----> 5\u001b[0m \u001b[43mprocess_video_yolo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 34\u001b[0m, in \u001b[0;36mprocess_video_yolo\u001b[1;34m(input_path, output_path, model, class_names)\u001b[0m\n\u001b[0;32m     31\u001b[0m out \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(output_path, cv2\u001b[38;5;241m.\u001b[39mVideoWriter_fourcc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmp4v\u001b[39m\u001b[38;5;124m'\u001b[39m), fps, (frame_width, frame_height))\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'cv2.VideoCapture' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "input_video_path = 'Fighting028_x264.mp4'\n",
    "output_video_path = 'OutputFighting028_x264.mp4'\n",
    "class_names = model.names\n",
    "\n",
    "process_video_yolo(input_video_path, output_video_path, model, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed58e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
